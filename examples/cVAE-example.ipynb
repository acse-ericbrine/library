{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7r0q-LczFP3",
    "outputId": "c29bfad6-bdb4-49bb-9fdb-8855d3d7a408"
   },
   "outputs": [],
   "source": [
    "!pip install pycm livelossplot\n",
    "!pip install torchsummary \n",
    "!pip install tsne_torch\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import FashionMNIST, MNIST\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "from tsne_torch import TorchTSNE as TSNE\n",
    "from livelossplot import PlotLosses\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mPh2tq1BWWf"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcs1IgoZVbM6",
    "outputId": "fa5e9309-c58a-4d84-a699-099481bb2543"
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Xq-9wiWBVlc",
    "outputId": "17f3fa52-0215-46f3-ef1c-0fd6d19b24e4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT8n0p4T4030"
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmrMMrHidwok"
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke_sqx_3VlWm"
   },
   "outputs": [],
   "source": [
    "# Load the FashionMNIST dataset and specify the transformations.\n",
    "fashion_mnist_dataset = FashionMNIST(\"./\", \n",
    "                                     transform=transforms.Compose([\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                         ]), \n",
    "                                     target_transform=torchvision.transforms.Compose([\n",
    "                                         lambda x:torch.LongTensor([x])\n",
    "                                        ]),\n",
    "                                     download=True, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxK7mM7bVnFb",
    "outputId": "8336aa62-64ab-4f78-c96a-fadc780c9749"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5btKw09YRkl",
    "outputId": "9bce5959-5b97-44ff-95ff-69e200d52116"
   },
   "outputs": [],
   "source": [
    "class_to_idx = fashion_mnist_dataset.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmuR39vdYft2",
    "outputId": "576a163b-f284-4947-c230-c12db342b344"
   },
   "outputs": [],
   "source": [
    "Counter(fashion_mnist_dataset.targets.to('cpu').detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCJcB2RZkNNv",
    "outputId": "fe6739f0-6504-4f80-f157-30bace803335"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_dataset.data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeyw9Dm-itgi"
   },
   "source": [
    "#### Plotting 10 samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6PuEum2pd4AJ",
    "outputId": "16633ca6-1539-4ad5-e54b-79d8471570fc"
   },
   "outputs": [],
   "source": [
    "def plot_classes(dataset, num_per_class=10):\n",
    "  class_counts = defaultdict(int)\n",
    "  images = []\n",
    "  for img, label_tensor in zip(dataset.data, dataset.targets):\n",
    "    label = label_tensor.item()\n",
    "    if class_counts[label] < 10:\n",
    "      images.append((img.to('cpu').detach().numpy(), label))\n",
    "      class_counts[label] += 1\n",
    "\n",
    "  images = [x for x in sorted(images, key=lambda t: t[1])]\n",
    "  _, ax = plt.subplots(10, 10, figsize=[20, 20])\n",
    "  for i, img in enumerate(images):\n",
    "    ax[img[1], i % 10].imshow(img[0].squeeze(), cmap='gray')\n",
    "\n",
    "plot_classes(fashion_mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7QxktjHdoYy"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=fashion_mnist_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = models.Conditional_VAE(20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXp-2EEEBssL"
   },
   "outputs": [],
   "source": [
    "groups = {'Loss': ['VAE_Loss']}\n",
    "\n",
    "liveloss = PlotLosses(groups=groups)\n",
    "\n",
    "# Set hyperparameters\n",
    "lr = 0.0001\n",
    "latent_dims = 50\n",
    "epochs = 30\n",
    "\n",
    "recon_losses = []\n",
    "kl_divs = []\n",
    "\n",
    "def train(vae, data, kl_div_on=True, epochs=10, device='cpu', lr=1e-4):\n",
    "\n",
    "  # Instantiate the optimizer\n",
    "  opt = torch.optim.Adam(vae.parameters(), lr=lr, betas=(0.5,0.9))\n",
    "  vae.train()\n",
    "  for epoch in range(1, epochs+1): \n",
    "    logs = {}\n",
    "    last_loss = 0\n",
    "    for batch, label in (data): \n",
    "      batch = batch.to(device) \n",
    "      label = label.to(device)\n",
    "      opt.zero_grad()\n",
    "\n",
    "      # Input batch to model\n",
    "      x_hat, kl_div = vae(batch, label) \n",
    "\n",
    "      # Calculate loss\n",
    "      loss = ((batch - x_hat)**2).mean() + kl_div \n",
    "\n",
    "      # Update model\n",
    "      loss.backward()\n",
    "      opt.step()\n",
    "\n",
    "      logs['VAE_Loss'] = loss.to('cpu').detach().numpy()\n",
    "      recon_losses.append(((batch - x_hat)**2).mean().to('cpu').detach().numpy())\n",
    "      kl_divs.append(kl_div.to('cpu').detach().numpy())\n",
    "    \n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "    print(recon_losses)\n",
    "    if(np.mod(epoch, 5) == 0):\n",
    "      torch.save(vae.state_dict(), \"./VAE.pth\".format(epoch))\n",
    "  return vae\n",
    "\n",
    "\n",
    "conditional_vae = Conditional_VAE(latent_dims).to(device)\n",
    "conditional_vae = train(conditional_vae.train(True), train_loader, lr=lr, epochs=epochs, device=device)\n",
    "conditional_vae.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "gzMq6nln36Ss",
    "outputId": "a5566608-3e89-4114-bf43-0f68873863a0"
   },
   "outputs": [],
   "source": [
    "vae_30_epochs = plt.imread(\"/content/gdrive/My Drive/images/vae_training.png\", format='png')\n",
    "\n",
    "f, axarr = plt.subplots(figsize=(10,10) )\n",
    "axarr.imshow(vae_30_epochs)\n",
    "\n",
    "axarr.title.set_text('VAE Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sznVYbsPqEwg"
   },
   "source": [
    "#### Plotting the latent space\n",
    "\n",
    "Using T-SNE to reduce the dimensions of some latent space samples to 2 so that they can be plotted. The data appears to be fairly normally distributed although there are some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LI6XEAX92Ffz",
    "outputId": "91e53cf6-70d0-41a7-9e7a-4742420ec3e8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_2D_latent_space(autoencoder, data, num_batches=40):\n",
    "    for n , (x, y) in enumerate(data):  \n",
    "        z, KL = autoencoder.vae_latent_space(autoencoder.encoder(x.to(device), y.to(device)))\n",
    "        z = z.to('cpu').detach().numpy() \n",
    "        z = TSNE(n_components=2, perplexity=30, n_iter=100, verbose=True).fit_transform(z)\n",
    "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10')\n",
    "        if n > num_batches:\n",
    "          plt.colorbar()\n",
    "          break\n",
    "plot_2D_latent_space(conditional_vae, train_loader)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kHy-BpZqC9L"
   },
   "source": [
    "#### Reconstructed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "uMEnY2_vFLEq",
    "outputId": "c36e15fb-b96f-4a1d-e298-a9b30c849f07"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))  # Get the first batch of images\n",
    "\n",
    "_, ax = plt.subplots(2, 5, figsize=[15, 6])\n",
    "for n, idx  in enumerate(torch.randint(0,images.shape[0], (5,))):\n",
    "  recon, _ = conditional_vae(images[idx].unsqueeze(0).cuda(), labels[idx].unsqueeze(0).cuda())  # Are mu and sigma correct\n",
    "  ax[0, n].imshow(images[idx].squeeze(), cmap=\"gray\")\n",
    "  ax[1, n].imshow(recon.cpu().detach().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIY7-reYq9hI"
   },
   "source": [
    "#### Generated Images \n",
    "\n",
    "Generate new images from random z vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "MpXVJQ4R_lLz",
    "outputId": "b7a04af0-29f7-4aed-fca1-c06326c62d08"
   },
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "\n",
    "def plot_samples(vae):\n",
    "  with torch.no_grad():\n",
    "      test_z, labels = torch.rand(batch_size, latent_dims).to(device).float().to(device), torch.linspace(0,9,10).repeat(10).to(device).long().view(-1, 1)\n",
    "      generated = vae.decoder(vae.activationOut(vae.latentOut(test_z)), labels).to('cpu').detach().numpy()\n",
    "  fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n",
    "  for ax, img in zip(axarr.flatten(), generated):\n",
    "    ax.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "\n",
    "plot_samples(conditional_vae)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
