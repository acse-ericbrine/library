{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7r0q-LczFP3",
    "outputId": "c29bfad6-bdb4-49bb-9fdb-8855d3d7a408"
   },
   "outputs": [],
   "source": [
    "# !pip install pycm livelossplot\n",
    "# !pip install torchsummary \n",
    "# !pip install tsne_torch\n",
    "\n",
    "# %pylab inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import FashionMNIST, MNIST\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "from tsne_torch import TorchTSNE as TSNE\n",
    "from livelossplot import PlotLosses\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from models import cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mPh2tq1BWWf"
   },
   "outputs": [],
   "source": [
    " \n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcs1IgoZVbM6",
    "outputId": "fa5e9309-c58a-4d84-a699-099481bb2543"
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Xq-9wiWBVlc",
    "outputId": "17f3fa52-0215-46f3-ef1c-0fd6d19b24e4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT8n0p4T4030"
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmrMMrHidwok"
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke_sqx_3VlWm"
   },
   "outputs": [],
   "source": [
    "# Load the FashionMNIST dataset and specify the transformations.\n",
    "fashion_mnist_dataset = FashionMNIST(\"./\", \n",
    "                                     transform=transforms.Compose([\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                         ]), \n",
    "                                     target_transform=torchvision.transforms.Compose([\n",
    "                                         lambda x:torch.LongTensor([x])\n",
    "                                        ]),\n",
    "                                     download=True, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxK7mM7bVnFb",
    "outputId": "8336aa62-64ab-4f78-c96a-fadc780c9749"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5btKw09YRkl",
    "outputId": "9bce5959-5b97-44ff-95ff-69e200d52116"
   },
   "outputs": [],
   "source": [
    "class_to_idx = fashion_mnist_dataset.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmuR39vdYft2",
    "outputId": "576a163b-f284-4947-c230-c12db342b344"
   },
   "outputs": [],
   "source": [
    "Counter(fashion_mnist_dataset.targets.to('cpu').detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCJcB2RZkNNv",
    "outputId": "fe6739f0-6504-4f80-f157-30bace803335"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_dataset.data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeyw9Dm-itgi"
   },
   "source": [
    "#### Plotting 10 samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6PuEum2pd4AJ",
    "outputId": "16633ca6-1539-4ad5-e54b-79d8471570fc"
   },
   "outputs": [],
   "source": [
    "def plot_classes(dataset, num_per_class=10):\n",
    "  class_counts = defaultdict(int)\n",
    "  images = []\n",
    "  for img, label_tensor in zip(dataset.data, dataset.targets):\n",
    "    label = label_tensor.item()\n",
    "    if class_counts[label] < 10:\n",
    "      images.append((img.to('cpu').detach().numpy(), label))\n",
    "      class_counts[label] += 1\n",
    "\n",
    "  images = [x for x in sorted(images, key=lambda t: t[1])]\n",
    "  _, ax = plt.subplots(10, 10, figsize=[20, 20])\n",
    "  for i, img in enumerate(images):\n",
    "    ax[img[1], i % 10].imshow(img[0].squeeze(), cmap='gray')\n",
    "\n",
    "plot_classes(fashion_mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7QxktjHdoYy"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=fashion_mnist_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "G = cGAN.Generator()\n",
    "D = cGAN.Discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvHIL_ItE0xG"
   },
   "outputs": [],
   "source": [
    "# Define loss\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "# Define dimensions of noise vector input into generator\n",
    "z_dim = 100\n",
    "\n",
    "# set learning rate\n",
    "lr = 0.0001\n",
    "\n",
    "def D_train(G, D, D_optimizer, x, label):\n",
    "    D.train()\n",
    "    D_optimizer.zero_grad()\n",
    "\n",
    "    # train discriminator on real data -- assign high score (use 1 here)\n",
    "    x_real, y_real = x.view(-1, 28*28), torch.ones((batch_size, 1))  # we are assigning the label 'real data' to the samples (don't care anymore about what number they are)\n",
    "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
    "\n",
    "    # Get output from real image\n",
    "    D_output = D(x_real, label)\n",
    "\n",
    "    # Calculate loss from real images. Use label smoothing for y_real.\n",
    "    D_real_loss = criterion(D_output, y_real-0.1)\n",
    "\n",
    "    # train discriminator on fake data -- assign low score (use 0 here)\n",
    "    # sample vector and produce generator output\n",
    "    z = torch.randn(batch_size, 100, 1, 1).to(device)\n",
    "\n",
    "    # Create random labels.\n",
    "    label_fake = torch.randint(0, 9, (batch_size, 1)).to(device)\n",
    "\n",
    "    # Generate fake image.\n",
    "    x_fake, y_fake = G(z, label_fake), torch.zeros((batch_size, 1)).to(device)\n",
    "\n",
    "    # Get discriminator output from fake images.\n",
    "    D_output = D(x_fake, label_fake)\n",
    "\n",
    "    # Calculate loss from fake images. Use label smoothing for y_fake.\n",
    "    D_fake_loss = criterion(D_output, y_fake+0.1)\n",
    "\n",
    "    # Add real and fake loss.\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "    # Update model.\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "        \n",
    "    return  D_loss.data.item()\n",
    "\n",
    "def G_train(G, D, G_optimizer, x, label):\n",
    "    G.train()\n",
    "    G_optimizer.zero_grad()\n",
    "\n",
    "    # Create random labels.\n",
    "    random_label = torch.randint(0, 9, (batch_size, 1)).to(device)\n",
    "    \n",
    "    # Create random vector for input to generator\n",
    "    z = torch.randn(batch_size, 100, 1, 1).to(device)\n",
    "\n",
    "    # Generate fake images.\n",
    "    G_output = G(z, random_label)\n",
    "\n",
    "    # Get output of discriminator with fake images.\n",
    "    D_output = D(G_output, random_label)\n",
    "\n",
    "    # Calculate loss from generated images.\n",
    "    y = torch.ones((batch_size, 1)).to(device)\n",
    "    G_loss = criterion(D_output, y)\n",
    "\n",
    "    # Update model.\n",
    "    G_loss.backward()\n",
    "    G_optimizer.step()\n",
    "        \n",
    "    return G_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77o7bFidJltL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "id": "y0DxGWEJA9nS",
    "outputId": "f023c1bc-9cd1-4b62-aefe-2845c8959858"
   },
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "\n",
    "start_epoch = 1\n",
    "load_model = False\n",
    "n_epoch = 50 \n",
    "groups = {'Loss': ['D_Loss', 'G_Loss']}\n",
    "liveloss = PlotLosses(groups=groups)\n",
    "\n",
    "generator_path = \"/content/gdrive/My Drive/models/Generator_50.pth\"\n",
    "discriminator_path = \"/content/gdrive/My Drive/models/Discriminator_50.pth\"\n",
    "\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "# Instantiate optimizers for G and D\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr = lr, betas = (0.5, 0.9))\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr = lr, betas = (0.5, 0.9))\n",
    "\n",
    "# Used to load existing model.\n",
    "if load_model:\n",
    "  G_checkpoint = torch.load(generator_path)\n",
    "  G.load_state_dict(G_checkpoint['model_state_dict'])\n",
    "  G_optimizer.load_state_dict(G_checkpoint['optimizer_state_dict'])\n",
    "\n",
    "  D_checkpoint = torch.load(discriminator_path)\n",
    "  D.load_state_dict(D_checkpoint['model_state_dict'])\n",
    "  D_optimizer.load_state_dict(D_checkpoint['optimizer_state_dict'])\n",
    "\n",
    "  start_epoch = D_checkpoint['epoch']\n",
    "\n",
    "  G.train()\n",
    "  D.train()\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+n_epoch+1):  \n",
    "  D_losses, G_losses = [], []\n",
    "  logs = {}\n",
    "  for batch_idx, (x, label) in enumerate(train_loader):\n",
    "    x, label = x.to(device), label.to(device)\n",
    "\n",
    "    # Train discriminator and generator\n",
    "    logs['D_Loss'] = D_train(G, D, D_optimizer, x, label)\n",
    "    logs['G_Loss'] = G_train(G, D, G_optimizer, x, label)\n",
    "  liveloss.update(logs)\n",
    "  liveloss.draw()\n",
    "\n",
    "  # save every 10 epochs\n",
    "  if(np.mod(epoch, 10) == 0):\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': G.state_dict(),\n",
    "            'optimizer_state_dict': G_optimizer.state_dict(),\n",
    "            'loss': logs['G_Loss'],\n",
    "            }, generator_path)\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': D.state_dict(),\n",
    "            'optimizer_state_dict': D_optimizer.state_dict(),\n",
    "            'loss': logs['D_Loss'],\n",
    "            }, discriminator_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "1Za2tXx6JpEd",
    "outputId": "3fc8a586-0d9e-42bd-8433-e6328b61be5d"
   },
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "\n",
    "## Load the generator\n",
    "# G = Generator()\n",
    "# G.load_state_dict(torch.load(generator_path))\n",
    "# G.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Generate random inputs for testing.\n",
    "    test_z, labels = torch.randn(batch_size, 100, 1, 1).to(device), torch.linspace(0,9,10).repeat(10).to(device).long().view(-1, 1)\n",
    "    generated = G(test_z, labels)\n",
    "\n",
    "    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n",
    "fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n",
    "for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 28, 28).cpu()):\n",
    "  ax.imshow(img, cmap=\"gray\")\n",
    "plt.title('Epoch = {:03d}'.format(epoch-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sty949KIGXtL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
